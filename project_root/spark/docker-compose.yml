version: "3"

services:
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master   # 중요!
      # - SPARK_MASTER_PORT=7077
      # - SPARK_MASTER_WEBUI_PORT=8085
    command: >
      bash -c "/opt/spark/sbin/start-master.sh && tail -f /opt/spark/logs/spark--org.apache.spark.deploy.master*.out"
    ports:
      - "8085:8080"
      - "7077:7077"
    volumes:
      - ../airflow/dags:/opt/airflow/dags
    networks:
      - spark-network

  spark-worker-1:
    image: apache/spark:3.5.0
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
    container_name: spark-worker-1
    depends_on:
      - spark-master
    command: >
      bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /opt/spark/logs/spark--org.apache.spark.deploy.worker*.out"
    ports:
      - "8081:8081"
    volumes:
      - ../airflow/dags:/opt/airflow/dags
    networks:
      - spark-network

  spark-worker-2:
    image: apache/spark:3.5.0
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
    container_name: spark-worker-2
    depends_on:
      - spark-master
    command: >
      bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /opt/spark/logs/spark--org.apache.spark.deploy.worker*.out"
    ports:
      - "8082:8081"
    volumes:
      - ../airflow/dags:/opt/airflow/dags
    networks:
      - spark-network

  # spark-history:
  #   image: apache/spark:3.5.0
  #   container_name: spark-history
  #   command: >
  #     bash -c "/opt/spark/sbin/start-history-server.sh && tail -f /opt/spark/logs/spark--org.apache.spark.deploy.history*.out"
  #   ports:
  #     - "18080:18080"
  #   volumes:
  #     - ./spark-events:/tmp/spark-events
  #   networks:
  #     - spark-network

networks:
  spark-network:
    name: spark-network
