from airflow import DAG
from airflow.decorators import task
from datetime import datetime
from airflow.hooks.base import BaseHook
import boto3
import os

aws_conn = BaseHook.get_connection("aws_default")
# --- í™˜ê²½ ë³€ìˆ˜ë¡œ AWS ì ‘ê·¼ í‚¤ë¥¼ ì„¤ì • (Airflow Connection ë˜ëŠ” Envì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID", aws_conn.login)
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY", aws_conn.password)
AWS_REGION = os.getenv("AWS_REGION", "us-east-2")
# --- ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ ì„¤ì •
S3_BUCKET = "databricks-workspace-stack-60801-bucket" # "samples/" # "your-bucket-name"
S3_KEY = "samples/data.csv" # "path/to/your/file.csv"       # ì˜ˆ: data/sample.csv
# LOCAL_SAVE_PATH = "/opt/airflow/dags/file.csv" # "/opt/airflow/data/file.csv"
LOCAL_SAVE_PATH = "/opt/airflow/dags/file.csv" # "/opt/airflow/data/file.csv"

# DAG ì •ì˜
with DAG(
    dag_id="s3_download_dag",
    description="Download CSV file from S3 using boto3 (Airflow 3.x)",
    start_date=datetime(2025, 1, 1),
    schedule=None,           # Airflow 3.xì—ì„œëŠ” schedule_interval ëŒ€ì‹  schedule ì‚¬ìš©
    catchup=False,
    tags=["test", "boto3"],
) as dag:

    @task()
    def say_hello():
        print("âœ… Hello, World from Airflow 3.x running on k3d!")

    @task()
    def download_csv_from_s3():
        """S3ì—ì„œ CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
        print("ðŸš€ Connecting to S3...")

        # boto3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        s3 = boto3.client(
            "s3",
            region_name=AWS_REGION,
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
        )

        # ë¡œì»¬ ì €ìž¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(LOCAL_SAVE_PATH), exist_ok=True)

        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        print(f"Downloading s3://{S3_BUCKET}/{S3_KEY} â†’ {LOCAL_SAVE_PATH}")
        s3.download_file(S3_BUCKET, S3_KEY, LOCAL_SAVE_PATH)

        print("âœ… Download completed successfully!")

        # ê°„ë‹¨í•œ íŒŒì¼ ê²€ì¦
        if os.path.exists(LOCAL_SAVE_PATH):
            size = os.path.getsize(LOCAL_SAVE_PATH)
            print(f"ðŸ“„ File saved: {LOCAL_SAVE_PATH} ({size} bytes)")
        else:
            raise FileNotFoundError("âŒ Download failed, file not found locally!")

    # Task ì‹¤í–‰
    say_hello() >> download_csv_from_s3()


